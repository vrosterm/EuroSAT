{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Jupyter notebook is sourced here: https://medium.com/@rekalantar/variational-auto-encoder-vae-pytorch-tutorial-dce2d2fe0f5f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "voaWjz0Z0VoP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torchvision.utils import save_image, make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svlrOe-jl_Ue"
   },
   "outputs": [],
   "source": [
    "# create a transofrm to apply to each datapoint\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# download the MNIST datasets\n",
    "path = \"~/datasets\"\n",
    "train_dataset = MNIST(path, transform=transform, download=True)\n",
    "test_dataset = MNIST(path, transform=transform, download=True)\n",
    "\n",
    "# create train and test dataloaders\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "id": "Uv247-ZrCURC",
    "outputId": "d304f867-61e3-4115-d2ee-ae97f04be86d"
   },
   "outputs": [],
   "source": [
    "# get 25 sample training images for visualization\n",
    "dataiter = iter(train_loader)\n",
    "image = next(dataiter)\n",
    "\n",
    "num_samples = 25\n",
    "sample_images = [image[0][i, 0] for i in range(num_samples)]\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "grid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.1)\n",
    "\n",
    "for ax, im in zip(grid, sample_images):\n",
    "    ax.imshow(im, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ezw2ckDTmSJw"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=784, hidden_dim=512, latent_dim=256):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.mean = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.var = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "        self.training = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LeakyReLU(self.linear1(x))\n",
    "        x = self.LeakyReLU(self.linear2(x))\n",
    "\n",
    "        mean = self.mean(x)\n",
    "        log_var = self.var(x)\n",
    "        return mean, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_m2Nqv1enW5J"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim=784, hidden_dim=512, latent_dim=256):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.linear2 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.linear1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, output_dim)\n",
    "        self.LeakyReLU = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.LeakyReLU(self.linear2(x))\n",
    "        x = self.LeakyReLU(self.linear1(x))\n",
    "\n",
    "        x_hat = torch.sigmoid(self.output(x))\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h672csE-nYNH"
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, input_dim=784, hidden1_dim=400, hidden2_dim=200, latent_dim=2, device=device\n",
    "    ):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden1_dim = hidden1_dim\n",
    "        self.hidden2_dim = hidden2_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = device\n",
    "\n",
    "        # encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden1_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden1_dim, hidden2_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        ).to(device)\n",
    "\n",
    "        # latent mean and Cholesky decomp of covariance\n",
    "        self.mean_layer = nn.Linear(hidden2_dim, latent_dim, device=device)\n",
    "        self.chol_layer = nn.Linear(\n",
    "            hidden2_dim, (latent_dim * (latent_dim + 1)) // 2, device=device\n",
    "        )\n",
    "\n",
    "        # decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden2_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden2_dim, hidden1_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(hidden1_dim, input_dim),\n",
    "            nn.Sigmoid(),\n",
    "        ).to(device)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        mean, chol = self.mean_layer(x), self.chol_layer(x)\n",
    "        return mean, chol\n",
    "\n",
    "    def reparameterization(self, mean, chol):\n",
    "        epsilon = torch.randn_like(mean, device=self.device)\n",
    "        batch_size = mean.shape[0]\n",
    "        L = torch.zeros(batch_size, self.latent_dim, self.latent_dim, device=self.device)\n",
    "        tril_indices = torch.tril_indices(\n",
    "            self.latent_dim, self.latent_dim, offset=0, device=self.device\n",
    "        )\n",
    "        L[:, tril_indices[0], tril_indices[1]] = chol\n",
    "        z = mean + torch.einsum(\"bij,bj->bi\", L, epsilon)\n",
    "        return z\n",
    "\n",
    "    def decode(self, x):\n",
    "        return self.decoder(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean, chol = self.encode(x)\n",
    "        z = self.reparameterization(mean, chol)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wOuxwnnVnbBJ"
   },
   "outputs": [],
   "source": [
    "model = VAE().to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RlwQdnotney0"
   },
   "outputs": [],
   "source": [
    "def loss_function(x, x_hat, mean, chol):\n",
    "    reproduction_loss = nn.functional.binary_cross_entropy(x_hat, x, reduction=\"sum\")\n",
    "\n",
    "    batch_size = mean.shape[0]\n",
    "    L = torch.zeros(batch_size, model.latent_dim, model.latent_dim, device=model.device)\n",
    "    tril_indices = torch.tril_indices(\n",
    "        model.latent_dim, model.latent_dim, offset=0, device=model.device\n",
    "    )\n",
    "    L[:, tril_indices[0], tril_indices[1]] = chol\n",
    "\n",
    "    Sigma = torch.einsum(\"bij,bkj->bik\", L, L)\n",
    "\n",
    "    KLD = 0.5 * (\n",
    "        torch.mean(torch.sum(mean.pow(2), axis=-1))\n",
    "        + torch.mean(torch.sum(torch.diagonal(Sigma, offset=0, dim1=-2, dim2=-1), axis=-1))\n",
    "        - torch.mean(torch.linalg.slogdet(Sigma).logabsdet)\n",
    "        - model.latent_dim\n",
    "    )\n",
    "\n",
    "    return reproduction_loss + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwWtxYrUF826"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, device, x_dim=784):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        overall_loss = 0\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            x = x.view(batch_size, x_dim).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x_hat, mean, log_var = model(x)\n",
    "            loss = loss_function(x, x_hat, mean, log_var)\n",
    "\n",
    "            overall_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", overall_loss / (batch_idx * batch_size))\n",
    "    return overall_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VP-7CIF3GYUA",
    "outputId": "5eb1559e-33a9-4d82-80c0-87d85cad1e08"
   },
   "outputs": [],
   "source": [
    "train(model, optimizer, epochs=100, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gk18nyo0KVtW"
   },
   "outputs": [],
   "source": [
    "def generate_digit(latent_vec):\n",
    "    z_sample = torch.tensor([latent_vec], dtype=torch.float, device=model.device)\n",
    "    x_decoded = model.decode(z_sample)\n",
    "    digit = x_decoded.detach().cpu().reshape(28, 28)  # reshape vector to 2d array\n",
    "    plt.title(f\"[{latent_vec[0]},{latent_vec[1]}]\")\n",
    "    plt.imshow(digit, cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "id": "J0FQ7fcpbPm0",
    "outputId": "8aa95ee1-4d4a-4bf6-f553-abe931d0298e"
   },
   "outputs": [],
   "source": [
    "generate_digit([0, 1.0]), generate_digit([1.0, 0.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the embedding of the training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "encoded_reps = defaultdict(list)\n",
    "\n",
    "for batch_idx, (x, labels) in enumerate(train_loader):\n",
    "    x = x.view(batch_size, 784).to(device)\n",
    "    mean_reps, chol_rep = model.encode(x)\n",
    "    for rep, label in zip(mean_reps, labels):\n",
    "        encoded_reps[int(label)].append(rep.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.gca()\n",
    "for label in range(10):\n",
    "    ax.scatter(*zip(*encoded_reps[label]), s=1, label=str(label))\n",
    "\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Zj82AQQljC7"
   },
   "source": [
    "## Visualize the generative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SgFh4FOvKVmb"
   },
   "outputs": [],
   "source": [
    "def plot_latent_space(model, scale=5.0, n=25, digit_size=28, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    # construct a grid\n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float, device=model.device)\n",
    "            x_decoded = model.decode(z_sample)\n",
    "            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n",
    "            figure[\n",
    "                i * digit_size : (i + 1) * digit_size,\n",
    "                j * digit_size : (j + 1) * digit_size,\n",
    "            ] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.title(\"VAE Latent Space Visualization\")\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"z [0]\")\n",
    "    plt.ylabel(\"z [1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "T_TFzS92gvig",
    "outputId": "db43e66a-92c4-434c-fe12-c19df86bde60"
   },
   "outputs": [],
   "source": [
    "plot_latent_space(model, scale=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893
    },
    "id": "iaZxxvMQgxaO",
    "outputId": "9a12b1cb-89d4-4027-f61d-e41ea8dc5b3d"
   },
   "outputs": [],
   "source": [
    "plot_latent_space(model, scale=5.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
